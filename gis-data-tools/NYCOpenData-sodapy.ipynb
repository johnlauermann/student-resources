{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here\n",
    "This notebook contains scripts to fetch data from the NYC Open Data API. Set up the basic workflow in this section, and then I've included one example using 311 data. You can adapt this for any tabular dataset on NYC Open Data by changing the query in the client.get() function. \n",
    "\n",
    "This code is based in part on Mark Bauer's sodapy Tutorial for NYC Open Data (https://github.com/mebauer/sodapy-tutorial-nyc-opendata/tree/main). Thanks also to Darcy Krasne, who provided some template code for pulling from the NYC Open Data API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import pandas\n",
    "import geopandas\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from sodapy import Socrata\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up for Socrata API\n",
    "data_url = 'data.cityofnewyork.us'\n",
    "app_token = 'your token' # to get a token, create an NYC Open Data account then follow these steps: https://support.socrata.com/hc/en-us/articles/210138558-Generating-App-Tokens-and-API-Keys\n",
    "client = Socrata(data_url, app_token, timeout=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up workspaces and check database\n",
    "default_gdb = arcpy.mp.ArcGISProject(\"CURRENT\").defaultGeodatabase\n",
    "print(default_gdb)\n",
    "\n",
    "datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "datasets = [''] + datasets if datasets is not None else []\n",
    "\n",
    "for ds in datasets:\n",
    "    for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "        path = os.path.join(ds, fc)\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 311 data\n",
    "This pulls data on 311 service requests from the NYC Office of Technology and Innovation. It pulls 311 requests that referece \"Homeless\" from the most recent year. Data from https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize empty list\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set limits\n",
    "limit = 1000\n",
    "offset = 0\n",
    "max_attempts = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data \n",
    "def fetch_data(offset):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            results = client.get(\"erm2-nwe9\", \n",
    "                                 where=\"created_date between '2024-01-01T00:00:00' and '2024-12-31T23:59:59' AND complaint_type like '%Homeless%'\",\n",
    "                                 order=\"created_date DESC\",\n",
    "                                 limit=limit,\n",
    "                                 offset=offset)\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {str(e)}\")\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(\"Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                print(\"Max retries reached. Exiting.\")\n",
    "                sys.exit(1)\n",
    "\n",
    "# Loop through the data to avoid 1000 record limit on API\n",
    "start_time = time.time()\n",
    "try:\n",
    "    while True:\n",
    "        results = fetch_data(offset)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No more records to fetch.\")\n",
    "            break\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        offset += limit\n",
    "\n",
    "        print(f\"Fetched {len(all_results)} records so far...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pandas.DataFrame.from_records(all_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to spatial data\n",
    "sdf = pandas.DataFrame.spatial.from_xy(df=df,\n",
    "x_column='longitude',\n",
    "y_column='latitude',\n",
    "sr=4326)\n",
    "\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save to geodatabase\n",
    "sdf.spatial.to_featureclass(location=default_gdb+\"/data_311\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to CSV\n",
    "aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "default_folder = aprx.homeFolder\n",
    "file_path = os.path.join(default_folder, 'data_311.csv')\n",
    "data_shelters.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

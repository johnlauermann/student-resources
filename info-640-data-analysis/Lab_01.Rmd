---
title: "Lab_01"
author: "John Lauermann"
date: "`r Sys.Date()`"
output: github_document
---

# Lab 1: Explore data with easy-to-implement tests

In the first few labs of the semester, we'll explore various families of *exploratory data analysis* â€“ data mining and visualization techniques used to draw out patterns in a multi-dimensional data set. In this lab, we'll start by exploring the structure of a dataset with simple visualization techniques (histograms and scatterplots) and then assess patterns in the data using simple tests including correlation and t-tests.

#### Learning Outcomes:

By the end of the lab, you should be able to:

-   Interpret the distribution of individual variables using histograms and descriptive statistics.

-   Interpret the bivariate relationships using scatterplots and correlation tests.

-   Test for differences between groups using t-tests.

To implement these tests, we'll use the NYC Open Data API to access the city's Primary Land Use Tax Lot Output (PLUTO) database. This is a cadastral dataset describing zoning, land use, taxation, and ownership of every property parcel in New York City.

# Getting started

```{r}
library(dplyr)   # for data management
library(ggplot2) # for data visualization
library(stringr) # for managing string data
library(kim)     # for skewness/kurtosis calculations
```

```{r}
# set the working directory
wd <- getwd()  # wherever your script is saved, save the file path as a variable
setwd(wd)      # set using that file path
```

The data are available [here](https://data.cityofnewyork.us/City-Government/Primary-Land-Use-Tax-Lot-Output-PLUTO-/64uk-42ks/about_data) on NYC Open Data. Download a copy of the CSV via the export button. Save to whatever folder this script is located in. Name the `csv` whatever you want to call it (I'll call my version `PLUTO.csv` ).

```{r}
# load the data
data <- read.csv("PLUTO.csv")
```

```{r}
# now some basic data verification
dim(data) # number of rows and columns
ls(data)  # list of all variables
```

# Q1: Histograms and descriptive stats

Choose a variable of interest. Visualize it on a histogram using `ggplot2`. Interpret its distribution using descriptive statistics (including mean, median, std. dev., skewness, and kurtosis).

For my workflow, I'll explore `assessland`, the assessed property value of the land. However, you'll notice that this variable has lots of zero values (mostly public-owned land) and some extremely large outliers. So I'll do some querying to only focus on residential properties with more than \$0 value, and normalize the variable per square footage of the building.

```{r}
# filter properties
residential <- data %>%
  filter(str_starts(zonedist1, "R") &
           (assessland > 0) &
           (assesstot > 0) &
           (lotarea > 0) &
           (unitsres > 0) &
           (resarea > 0) & 
           (numfloors > 0)
         ) %>%
  mutate(assessland_persqft = assessland / as.numeric(lotarea),
         assesstot_persqft = assesstot / as.numeric(resarea),
         LLC = ifelse(str_detect(ownername, "LLC"), 1, 0)
         )
```

```{r}
ggplot(data = residential, aes(x = assessland_persqft)) +  # defines the plot space
  geom_histogram(       # defines what kind of visualization 
    binwidth = 20,    # each bar represents this increment
    fill = "red",       # bar color
    color = "gray50",  # order color
    na.rm = TRUE) +    # ignore nulls
  labs(          
    title = "Residential Land in NYC", # add text
    subtitle = "Price per sq ft, 2025",
    caption = "Source: NYC Dept of City Planning",
    x = "$/sq.ft",
    y  = "Tax Lots"
  ) + 
  theme_minimal()  # choose a theme
```

```{r}
# now interpret descriptive statistics
mean(as.numeric(na.omit(residential$assessland_persqft)))
median(as.numeric(na.omit(residential$assessland_persqft)))
sd(as.numeric(na.omit(residential$assessland_persqft)))
max(as.numeric(na.omit(residential$assessland_persqft)))
min(as.numeric(na.omit(residential$assessland_persqft)))

```

```{r}
# interpret skewness 
skewness(residential$assessland_persqft, type = "pearson_2")  # using median
```

```{r}
# interpret kurtosis
kurtosis(residential$assessland_persqft)
```

# Q2: Scatterplots and correlation

Choose a second continuous variable that might explain your initial variable. Visualize the bivariate relationship with a scatterplot. Test it with an appropriate correlation test.

In my case, I'll use `numfloors` because I want to know if there's a relationship between land prices and vertical housing development.

```{r}
# scatterplot
ggplot(data = residential, 
       aes(x = assessland_persqft,
           y = as.numeric(numfloors))
       ) +   
  geom_point(color = "green", 
             alpha = .5) +  
  labs(
    title = "Residential real estate in NYC",
    x = "$/sq.ft.", 
    y = "Number of Floors", 
    caption = "Source: NYC Dept. of City Planning"
  )
```

```{r}
# test the correlation
cor.test(x = residential$assessland_persqft, 
         y = as.numeric(residential$numfloors), 
         method = "pearson")  # we can use this because the variables are continous
```

```{r}
# now try correlation with a categorical variable
cor.test(x = residential$assessland_persqft, 
         y = residential$LLC, 
         method = "kendall")
```

# Q3: t-tests

Now pick another variable to use for grouping. Use t-tests to assess whether there are differences across your original variable by group. Also interpret effect sizes, for example with Cohen's D.

For my grouping variable, I'll use `LLC`, a variable I calculated earlier to indicate whether a property is owned by an LLC. It's 1 if the term "LLC" appears in `ownername` and 0 otherwise.

```{r}
table(residential$LLC)
```

```{r}
# test to see if there are equal variances
# for simplicity, I'll subset the data
LLC_yes <- residential %>%
  select(assessland_persqft, LLC) %>%
  filter(LLC == 1)
LLC_no <- residential %>%
  select(assessland_persqft, LLC) %>%
  filter(LLC == 0)

# and then use a variance test
var.test(LLC_yes$assessland_persqft, LLC_yes$assessland_persqft)
```

```{r}
# now the t-test
t.test(x = LLC_yes$assessland_persqft, 
       y = LLC_no$assessland_persqft, 
       var.equal = TRUE)
```

```{r}
# and cohen's D
cohen_d(sample_1 = LLC_yes$assessland_persqft, sample_2 = LLC_no$assessland_persqft)
```

# Q4: chi-squared test

Finally, choose two categorical variables to assess in the data. Use a chi-squared test to interpret whether the groups are unrelated. Interpret the contingency tables and odds ratios too.

```{r}
# set up the chi-squared test
chi <- chisq.test(x = residential$borough, y = residential$LLC)
print(chi)
```

```{r}
# contingency tables
chi$expected
chi$observed
chi$residuals
chi$stdres
```

```{r}
# finally, some fisher tests to assess odds ratios
# first, let's calculate some simpler variables
borolist <- c("BK", "BX", "MN", "QN", "SI")
for (boro in borolist){
  column_name <- paste0("in_", boro)
  residential[[column_name]] <- ifelse(residential$borough == boro, 1, 0)
}
```

```{r}
# and run the tests
fisher.test(residential$in_BK, residential$LLC, simulate.p.value = TRUE, B = 1000)
fisher.test(residential$in_BX, residential$LLC, simulate.p.value = TRUE, B = 1000)
fisher.test(residential$in_MN, residential$LLC, simulate.p.value = TRUE, B = 1000)
fisher.test(residential$in_QN, residential$LLC, simulate.p.value = TRUE, B = 1000)
fisher.test(residential$in_SI, residential$LLC, simulate.p.value = TRUE, B = 1000)
```
